## Home Credit Default Risk 


<img src="https://raw.githubusercontent.com/GQ21/Data-Science-Projects/main/Credit_Risk/img_homecredit.png" align="centre">

I chose to participate in [Home Credit Default Risk kaggle competition](https://www.kaggle.com/c/home-credit-default-risk/overview) where I was challenged to make a model which would ensure that home credit clients capable of repayment wouldn't be rejected and the ones that potentialy default would be rejected. Main challenge was to analyze, clean, aggregate and merge provided Big Data - 7 dataframes which took over 2.5 GB of space. I explored multiple models and tested their speed. I experimented with different imputing, outliers detection, feature selection algorithms. Additionally I set a goal to get at least median private leaderboard score and I succeeded. I found that feature engineering was one of the leading factor in achieving high kaggle score.


### Tools
*   Python 3.6 
*   Jupyter Notebook 
*   Pandas
*   Scikit-Learn
*   Lightgbm
*   Matplotlib
*   Seaborn
*   Bayes_opt

## Status
Project is: _finished_